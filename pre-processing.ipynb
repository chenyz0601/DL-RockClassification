{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "it contains two large modules:\n",
    "process X and process Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import arcpy\n",
    "import numpy as np\n",
    "import os, glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arcpy.CheckExtension('ImageAnalyst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process X\n",
    "### X from sentinal 2 L2A data\n",
    "#### check bands and resolutions, resample all bands to 10m\n",
    "resolution 10m: band2(blue), band3(green), band4(red), band8(nir)<br>\n",
    "need to be resampled to R10m: band5, band6, band7, band8A, band11, band12<br>\n",
    "band1, band9, band10 are useless, only for correction\n",
    "so the total num of bands is 10<br>\n",
    "followed by ASTER band4-9 and Geo-physical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate NDVI\n",
    "set threshold as 0.3, band3 is red, band7 is NIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layer number and rock type\n",
    "| Layer | Rock |\n",
    "|-------|------|\n",
    "| 0     | Vegetation|\n",
    "| 1     | Unkown Rocks|\n",
    "| 2     | Carbonate_sediment|\n",
    "| 3     | Dolerite|\n",
    "| 4     | Feldspathic_sediment|\n",
    "| 5     | Felsic_volcanic|\n",
    "| 6     | Gneiss|\n",
    "| 7     | Granite|\n",
    "| 8     | Mafic_volcanic|\n",
    "| 9     | Quartz_sediment|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export training data X, Y with tile of 256 x 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split X and Y into tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.DeepRock.utils import split2Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = arcpy.Raster(r'C:\\Users\\yuch\\Documents\\ArcGIS\\Projects\\mount_isa\\mount_isa.gdb\\GEO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_min = []\n",
    "geo_max = []\n",
    "for i in range(geo.bandCount):\n",
    "    geo_min.append(float(arcpy.GetRasterProperties_management(geo, 'MINIMUM', 'Band_{0}'.format(i+1)).getOutput(0)))\n",
    "    geo_max.append(float(arcpy.GetRasterProperties_management(geo, 'MAXIMUM', 'Band_{0}'.format(i+1)).getOutput(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize input remote sensing data, and save as numpy array\n",
    "block_id = 4\n",
    "# read the raster block\n",
    "raster = arcpy.Raster('C:/Users/yuch/Documents/ArcGIS/Projects/mount_isa/BLOCK{0}.tif'.format(block_id))\n",
    "raster_num = arcpy.RasterToNumPyArray(raster)\n",
    "# Sentinel 2A data divided by 10000., ASTER divided by 1000.\n",
    "# geo data nomalized by (-min)/(max-min)\n",
    "for i in range(10):\n",
    "    raster_num[i,:,:] = raster_num[i,:,:] / 10000.\n",
    "    \n",
    "for i in range(10, 16):\n",
    "    raster_num[i,:,:] = raster_num[i,:,:] / 1000.\n",
    "    \n",
    "for i in range(16, 29):\n",
    "    raster_num[i,:,:] = (raster_num[i,:,:] - geo_min[i-16])/(geo_max[i-16] - geo_min[i-16])\n",
    "    \n",
    "np.save('./data/Blocks/block{0}'.format(block_id), raster_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save labels as numpy array\n",
    "for block_id in range(1, 5):\n",
    "    # read the raster block\n",
    "    raster = arcpy.Raster('C:/Users/yuch/Documents/ArcGIS/Projects/mount_isa/Labels_BLOCK{0}.tif'.format(block_id))\n",
    "    raster_num = arcpy.RasterToNumPyArray(raster)\n",
    "\n",
    "    np.save('./data/Blocks/labels_block{0}'.format(block_id), raster_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split into 336 tiles\n",
      "split into 336 tiles\n",
      "split into 420 tiles\n",
      "split into 420 tiles\n",
      "split into 340 tiles\n",
      "split into 340 tiles\n",
      "split into 294 tiles\n",
      "split into 294 tiles\n"
     ]
    }
   ],
   "source": [
    "# use block 1, 3, 4 as train data\n",
    "# and block 2 as test data\n",
    "split2Tiles('./data/train/X/', np.load('./data/Blocks/block1.npy'), suffix='block1')\n",
    "split2Tiles('./data/train/Y/', np.load('./data/Blocks/labels_block1.npy'), suffix='block1')\n",
    "split2Tiles('./data/train/X/', np.load('./data/Blocks/block3.npy'), suffix='block3')\n",
    "split2Tiles('./data/train/Y/', np.load('./data/Blocks/labels_block3.npy'), suffix='block3')\n",
    "split2Tiles('./data/train/X/', np.load('./data/Blocks/block4.npy'), suffix='block4')\n",
    "split2Tiles('./data/train/Y/', np.load('./data/Blocks/labels_block4.npy'), suffix='block4')\n",
    "split2Tiles('./data/test/X/', np.load('./data/Blocks/block2.npy'), suffix='block2')\n",
    "split2Tiles('./data/test/Y/', np.load('./data/Blocks/labels_block2.npy'), suffix='block2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split into 5655 tiles\n",
      "split into 5655 tiles\n"
     ]
    }
   ],
   "source": [
    "# split into tiles of 64X64\n",
    "split2Tiles('./data/block1_64/X/', np.load('./data/Blocks/block1.npy'), suffix='block1_64', x_size=64, y_size=64)\n",
    "split2Tiles('./data/block1_64/Y/', np.load('./data/Blocks/labels_block1.npy'), suffix='block1_64', x_size=64, y_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove tile with bad boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.DeepRock.utils import remove_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing tiles with bad boundary\n",
      "removing tiles with bad boundary\n"
     ]
    }
   ],
   "source": [
    "remove_boundary('./data/train/')\n",
    "remove_boundary('./data/test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concatenate numpy arrarys into raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "block_id = 1\n",
    "raster = arcpy.Raster('C:/Users/yuch/Documents/ArcGIS/Projects/mount_isa/Labels_BLOCK{0}.tif'.format(block_id))\n",
    "arr = np.load('./data/block{0}/Y.npy'.format(block_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = raster.extent.XMin + 9 * 256 * raster.meanCellWidth\n",
    "my = raster.extent.YMax - 6 * 256 * raster.meanCellHeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rst = arcpy.NumPyArrayToRaster(arr/10., arcpy.Point(mx, my), raster.meanCellWidth, raster.meanCellHeight)\n",
    "rst.save('./data/block{0}/Y.tif'.format(block_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_id = 1\n",
    "raster = arcpy.Raster('C:/Users/yuch/Documents/ArcGIS/Projects/mount_isa/Labels_BLOCK{0}.tif'.format(block_id))\n",
    "arr = np.load('./data/block{0}/preds_sent_ast.npy'.format(block_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = raster.extent.XMin + 9 * 256 * raster.meanCellWidth\n",
    "my = raster.extent.YMax - 6 * 256 * raster.meanCellHeight\n",
    "rst = arcpy.NumPyArrayToRaster(arr/10., arcpy.Point(mx, my), raster.meanCellWidth, raster.meanCellHeight)\n",
    "rst.save('./data/block{0}/preds_sent_ast.tif'.format(block_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merging all the sediments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge carbonate_sediment (2), Feldspathic_sediment (4) and Quartz_sediment (9)\n",
    "yy = np.load('./data/Blocks/labels_block1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = np.copy(yy[9,:,:])\n",
    "yy[2,:,:] += qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = np.delete(yy, 9, 0)\n",
    "yy = np.delete(yy, 4, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/Blocks/labels_block1_mergeS.npy', yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split into 5655 tiles\n"
     ]
    }
   ],
   "source": [
    "split2Tiles('./data/block1_64/Y_merged/', np.load('./data/Blocks/labels_block1_mergeS.npy'), suffix='block1_64', x_size=64, y_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing tiles with bad boundary\n"
     ]
    }
   ],
   "source": [
    "from src.DeepRock.utils import remove_boundary\n",
    "remove_boundary('./data/block1_64/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
